{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Adaptive Choropleth Mapper (ACM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading manifest: 100%|██████████| 2/2 [00:00<00:00, 1871.62entries/s]\n",
      "/opt/conda/lib/python3.7/site-packages/geosnap/_data.py:123: UserWarning: Unable to locate local census data. Streaming instead.\n",
      "If you plan to use census data repeatedly you can store it locally with the io.store_census function for better performance\n",
      "  \"Unable to locate local census data. Streaming instead.\\n\"\n",
      "Loading manifest: 100%|██████████| 5/5 [00:00<00:00, 7317.35entries/s]\n",
      "Loading manifest: 100%|██████████| 5/5 [00:00<00:00, 5550.96entries/s]\n",
      "Loading manifest: 100%|██████████| 2/2 [00:00<00:00, 2490.68entries/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geosnap import datasets\n",
    "from Adaptive_Choropleth_Mapper import Adaptive_Choropleth_Mapper_viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable names in \"variable\" column are needed to use built-in data from geosnap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>label</th>\n",
       "      <th>formula</th>\n",
       "      <th>ltdb</th>\n",
       "      <th>ncdb</th>\n",
       "      <th>census_1990_form</th>\n",
       "      <th>census_1990_table_column</th>\n",
       "      <th>census_2000_form</th>\n",
       "      <th>census_2000_table_column</th>\n",
       "      <th>acs</th>\n",
       "      <th>category</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>geoid</td>\n",
       "      <td>FIPS code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>geoid</td>\n",
       "      <td>GEO2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n_mexican_pop</td>\n",
       "      <td>persons of Mexican parentage or ancestry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mex</td>\n",
       "      <td>MEXIC</td>\n",
       "      <td>SF1</td>\n",
       "      <td>P0090001</td>\n",
       "      <td>SF1</td>\n",
       "      <td>PCT011004</td>\n",
       "      <td>B03001_004E</td>\n",
       "      <td>Ethnicity &amp; Immigration</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n_cuban_pop</td>\n",
       "      <td>persons of Cuban parentage or ancestry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cuban</td>\n",
       "      <td>CUBAN</td>\n",
       "      <td>SF1</td>\n",
       "      <td>P0090004</td>\n",
       "      <td>SF1</td>\n",
       "      <td>PCT011006</td>\n",
       "      <td>B03001_006E</td>\n",
       "      <td>Ethnicity &amp; Immigration</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n_puerto_rican_pop</td>\n",
       "      <td>persons of Puerto Rican parentage or ancestry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pr</td>\n",
       "      <td>PRICAN</td>\n",
       "      <td>SF1</td>\n",
       "      <td>P0090003</td>\n",
       "      <td>SF1</td>\n",
       "      <td>PCT011005</td>\n",
       "      <td>B03001_005E</td>\n",
       "      <td>Ethnicity &amp; Immigration</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n_russian_pop</td>\n",
       "      <td>persons of Russian/USSR parentage or ancestry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ruanc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SF3</td>\n",
       "      <td>P0330022</td>\n",
       "      <td>SF3</td>\n",
       "      <td>PCT016064+PCT016053+PCT016052+PCT016037</td>\n",
       "      <td>B04004_064E</td>\n",
       "      <td>Ethnicity &amp; Immigration</td>\n",
       "      <td>ruancXX (page 17 of LTDB codebook) suggests th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             variable                                          label formula  \\\n",
       "0               geoid                                      FIPS code     NaN   \n",
       "1       n_mexican_pop       persons of Mexican parentage or ancestry     NaN   \n",
       "2         n_cuban_pop         persons of Cuban parentage or ancestry     NaN   \n",
       "3  n_puerto_rican_pop  persons of Puerto Rican parentage or ancestry     NaN   \n",
       "4       n_russian_pop  persons of Russian/USSR parentage or ancestry     NaN   \n",
       "\n",
       "    ltdb     ncdb census_1990_form census_1990_table_column census_2000_form  \\\n",
       "0  geoid  GEO2010              NaN                      NaN              NaN   \n",
       "1    mex    MEXIC              SF1                 P0090001              SF1   \n",
       "2  cuban    CUBAN              SF1                 P0090004              SF1   \n",
       "3     pr   PRICAN              SF1                 P0090003              SF1   \n",
       "4  ruanc      NaN              SF3                 P0330022              SF3   \n",
       "\n",
       "                  census_2000_table_column          acs  \\\n",
       "0                                      NaN          NaN   \n",
       "1                                PCT011004  B03001_004E   \n",
       "2                                PCT011006  B03001_006E   \n",
       "3                                PCT011005  B03001_005E   \n",
       "4  PCT016064+PCT016053+PCT016052+PCT016037  B04004_064E   \n",
       "\n",
       "                  category                                              notes  \n",
       "0                      NaN                                                NaN  \n",
       "1  Ethnicity & Immigration                                                NaN  \n",
       "2  Ethnicity & Immigration                                                NaN  \n",
       "3  Ethnicity & Immigration                                                NaN  \n",
       "4  Ethnicity & Immigration  ruancXX (page 17 of LTDB codebook) suggests th...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.codebook().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linked Choropleth Map Visulaizations using ACM with built-in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/geosnap/_data.py:364: UserWarning: streaming remote data. Use `geosnap.io.store_census() to store the data locally for better performance\n",
      "  warn('streaming remote data. Use `geosnap.io.store_census() to store the data locally for better performance')\n",
      "/opt/conda/lib/python3.7/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To see your visualization, click the URL below:\n",
      "https://cybergisx.cigi.illinois.edu/user/suhanmappingideas/view/geosnap-viz/PYTHON_Quantitative_Data_VIZ/ACM_SD_ACM_only/index.html\n",
      "Advanced options are available in \n",
      "https://cybergisx.cigi.illinois.edu/user/suhanmappingideas/edit/geosnap-viz/PYTHON_Quantitative_Data_VIZ/ACM_SD_ACM_only/data/CONFIG_SD_ACM_only.js\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "        'title': \"Adaptive Choropleth Mapper\",\n",
    "        'filename_suffix': \"SD_ACM_only\",\n",
    "        'state_fips': None,    #fips code is avaiable for every US state at https://github.com/suhanmappingideas/geosnap-viz/blob/master/state_id.csv\n",
    "        'msa_fips': \"41740\",   #For more options: http://su-gis.iptime.org/LNE/pick_POI.html\n",
    "        'county_fips': None,   #county code is also availabe in the link right above. \n",
    "        'years': [1980, 1990, 2000, 2010],\n",
    "        'variables': [\n",
    "            \"p_nonhisp_white_persons\",\n",
    "            \"p_nonhisp_black_persons\",\n",
    "            \"p_hispanic_persons\",\n",
    "            \"p_native_persons\",\n",
    "            \"p_asian_persons\",\n",
    "            \"p_hawaiian_persons\",\n",
    "            \"p_asian_indian_persons\",\n",
    "            \"p_chinese_persons\",\n",
    "            \"p_filipino_persons\",\n",
    "            \"p_japanese_persons\",\n",
    "            \"p_korean_persons\",           \n",
    "        ],\n",
    "        'label': \"short_name\",                                       # variable, short_name or full_name\n",
    "        #'chart': \"Stacked_Chart\",    \n",
    "        #'chart': \"Correlogram\",\n",
    "        #'chart': \"Scatter Plot\",   \n",
    "        #'chart': \"Parallel Coordinates Plot\",    \n",
    "}\n",
    "Adaptive_Choropleth_Mapper_viz(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linked Choropleth Map Visulaizations using ACM with data received from users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tractID</th>\n",
       "      <th>n_asian_under_15</th>\n",
       "      <th>n_black_under_15</th>\n",
       "      <th>n_hispanic_under_15</th>\n",
       "      <th>n_native_under_15</th>\n",
       "      <th>n_white_under_15</th>\n",
       "      <th>n_persons_under_18</th>\n",
       "      <th>n_asian_over_60</th>\n",
       "      <th>n_black_over_60</th>\n",
       "      <th>n_hispanic_over_60</th>\n",
       "      <th>...</th>\n",
       "      <th>n_widowed_divorced</th>\n",
       "      <th>n_white_persons</th>\n",
       "      <th>year</th>\n",
       "      <th>n_total_housing_units_sample</th>\n",
       "      <th>p_white_over_60</th>\n",
       "      <th>p_black_over_60</th>\n",
       "      <th>p_hispanic_over_60</th>\n",
       "      <th>p_native_over_60</th>\n",
       "      <th>p_asian_over_60</th>\n",
       "      <th>p_disabled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17031010100</td>\n",
       "      <td>199.260498</td>\n",
       "      <td>642.615112</td>\n",
       "      <td>482.210419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>347.709564</td>\n",
       "      <td>1646.888062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.778149</td>\n",
       "      <td>11.955630</td>\n",
       "      <td>...</td>\n",
       "      <td>812.982849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980</td>\n",
       "      <td>2964.000000</td>\n",
       "      <td>6.403551</td>\n",
       "      <td>0.951022</td>\n",
       "      <td>0.190204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.407830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17031010201</td>\n",
       "      <td>86.901924</td>\n",
       "      <td>146.249573</td>\n",
       "      <td>170.977768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>519.291992</td>\n",
       "      <td>987.008057</td>\n",
       "      <td>16.956472</td>\n",
       "      <td>8.478236</td>\n",
       "      <td>12.010835</td>\n",
       "      <td>...</td>\n",
       "      <td>1049.181763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980</td>\n",
       "      <td>2804.883301</td>\n",
       "      <td>20.415481</td>\n",
       "      <td>0.148386</td>\n",
       "      <td>0.210214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296773</td>\n",
       "      <td>3.956968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17031010202</td>\n",
       "      <td>36.098076</td>\n",
       "      <td>60.750423</td>\n",
       "      <td>71.022232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.708023</td>\n",
       "      <td>409.991974</td>\n",
       "      <td>7.043527</td>\n",
       "      <td>3.521764</td>\n",
       "      <td>4.989165</td>\n",
       "      <td>...</td>\n",
       "      <td>435.818237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980</td>\n",
       "      <td>1165.116821</td>\n",
       "      <td>20.415482</td>\n",
       "      <td>0.148386</td>\n",
       "      <td>0.210214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296773</td>\n",
       "      <td>3.956968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17031010300</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>389.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1484.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980</td>\n",
       "      <td>3359.000000</td>\n",
       "      <td>26.352395</td>\n",
       "      <td>0.772798</td>\n",
       "      <td>0.865533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417311</td>\n",
       "      <td>2.998454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17031010400</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>358.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980</td>\n",
       "      <td>2363.000000</td>\n",
       "      <td>17.813015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288303</td>\n",
       "      <td>3.088962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>17031843700</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>513.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>17031843800</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>892.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>17031843900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>735.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>905.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>2321.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>17031980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>17031980100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5272 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tractID  n_asian_under_15  n_black_under_15  n_hispanic_under_15  \\\n",
       "0     17031010100        199.260498        642.615112           482.210419   \n",
       "1     17031010201         86.901924        146.249573           170.977768   \n",
       "2     17031010202         36.098076         60.750423            71.022232   \n",
       "3     17031010300         79.000000         81.000000           157.000000   \n",
       "4     17031010400          7.000000         10.000000            10.000000   \n",
       "...           ...               ...               ...                  ...   \n",
       "5267  17031843700         20.000000          0.000000            64.000000   \n",
       "5268  17031843800         46.000000        298.000000            12.000000   \n",
       "5269  17031843900          0.000000        623.000000             2.000000   \n",
       "5270  17031980000          0.000000          0.000000             0.000000   \n",
       "5271  17031980100          0.000000          0.000000             0.000000   \n",
       "\n",
       "      n_native_under_15  n_white_under_15  n_persons_under_18  \\\n",
       "0                   0.0        347.709564         1646.888062   \n",
       "1                   0.0        519.291992          987.008057   \n",
       "2                   0.0        215.708023          409.991974   \n",
       "3                   0.0        389.000000          698.000000   \n",
       "4                   0.0        234.000000          358.000000   \n",
       "...                 ...               ...                 ...   \n",
       "5267                0.0        320.000000          513.000000   \n",
       "5268                0.0        104.000000          583.000000   \n",
       "5269                0.0          0.000000          735.000000   \n",
       "5270                0.0          0.000000            0.000000   \n",
       "5271                0.0          0.000000            0.000000   \n",
       "\n",
       "      n_asian_over_60  n_black_over_60  n_hispanic_over_60  ...  \\\n",
       "0            0.000000        59.778149           11.955630  ...   \n",
       "1           16.956472         8.478236           12.010835  ...   \n",
       "2            7.043527         3.521764            4.989165  ...   \n",
       "3           27.000000        50.000000           56.000000  ...   \n",
       "4           14.000000         0.000000           23.000000  ...   \n",
       "...               ...              ...                 ...  ...   \n",
       "5267              NaN              NaN                 NaN  ...   \n",
       "5268              NaN              NaN                 NaN  ...   \n",
       "5269              NaN              NaN                 NaN  ...   \n",
       "5270              NaN              NaN                 NaN  ...   \n",
       "5271              NaN              NaN                 NaN  ...   \n",
       "\n",
       "      n_widowed_divorced  n_white_persons  year  n_total_housing_units_sample  \\\n",
       "0             812.982849              NaN  1980                   2964.000000   \n",
       "1            1049.181763              NaN  1980                   2804.883301   \n",
       "2             435.818237              NaN  1980                   1165.116821   \n",
       "3            1484.000000              NaN  1980                   3359.000000   \n",
       "4             712.000000              NaN  1980                   2363.000000   \n",
       "...                  ...              ...   ...                           ...   \n",
       "5267          182.000000              NaN  2010                    992.000000   \n",
       "5268          221.000000              NaN  2010                    892.000000   \n",
       "5269          905.000000              NaN  2010                   2321.000000   \n",
       "5270            0.000000              NaN  2010                      0.000000   \n",
       "5271            0.000000              NaN  2010                      0.000000   \n",
       "\n",
       "      p_white_over_60  p_black_over_60  p_hispanic_over_60  p_native_over_60  \\\n",
       "0            6.403551         0.951022            0.190204               0.0   \n",
       "1           20.415481         0.148386            0.210214               0.0   \n",
       "2           20.415482         0.148386            0.210214               0.0   \n",
       "3           26.352395         0.772798            0.865533               0.0   \n",
       "4           17.813015         0.000000            0.473641               0.0   \n",
       "...               ...              ...                 ...               ...   \n",
       "5267              NaN              NaN                 NaN               NaN   \n",
       "5268              NaN              NaN                 NaN               NaN   \n",
       "5269              NaN              NaN                 NaN               NaN   \n",
       "5270              NaN              NaN                 NaN               NaN   \n",
       "5271              NaN              NaN                 NaN               NaN   \n",
       "\n",
       "      p_asian_over_60  p_disabled  \n",
       "0            0.000000    3.407830  \n",
       "1            0.296773    3.956968  \n",
       "2            0.296773    3.956968  \n",
       "3            0.417311    2.998454  \n",
       "4            0.288303    3.088962  \n",
       "...               ...         ...  \n",
       "5267              NaN         NaN  \n",
       "5268              NaN         NaN  \n",
       "5269              NaN         NaN  \n",
       "5270              NaN         NaN  \n",
       "5271              NaN         NaN  \n",
       "\n",
       "[5272 rows x 192 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_attributes = pd.read_csv(\"attributes/Chicago_1980_1990_2000_2010.csv\", dtype={'geoid':str})\n",
    "input_attributes = input_attributes.rename(columns={'geoid': 'tractID'})\n",
    "input_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tractID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17031010300</td>\n",
       "      <td>POLYGON ((-87.67133 42.01937, -87.67121 42.019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17031010400</td>\n",
       "      <td>POLYGON ((-87.66345 42.01283, -87.66321 42.012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17031010600</td>\n",
       "      <td>POLYGON ((-87.67059 42.00537, -87.67046 42.005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17031020100</td>\n",
       "      <td>POLYGON ((-87.69024 42.01265, -87.69024 42.012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17031280800</td>\n",
       "      <td>POLYGON ((-87.69151 41.88111, -87.69147 41.881...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>17031823901</td>\n",
       "      <td>POLYGON ((-87.85680 41.67987, -87.85676 41.680...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>17031826800</td>\n",
       "      <td>POLYGON ((-87.67975 41.64819, -87.67910 41.648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>17031710300</td>\n",
       "      <td>POLYGON ((-87.66361 41.75768, -87.66330 41.757...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>17031828506</td>\n",
       "      <td>POLYGON ((-87.55864 41.54282, -87.55850 41.542...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>17031825600</td>\n",
       "      <td>POLYGON ((-87.72777 41.58756, -87.72765 41.587...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1318 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tractID                                           geometry\n",
       "0     17031010300  POLYGON ((-87.67133 42.01937, -87.67121 42.019...\n",
       "1     17031010400  POLYGON ((-87.66345 42.01283, -87.66321 42.012...\n",
       "2     17031010600  POLYGON ((-87.67059 42.00537, -87.67046 42.005...\n",
       "3     17031020100  POLYGON ((-87.69024 42.01265, -87.69024 42.012...\n",
       "4     17031280800  POLYGON ((-87.69151 41.88111, -87.69147 41.881...\n",
       "...           ...                                                ...\n",
       "1313  17031823901  POLYGON ((-87.85680 41.67987, -87.85676 41.680...\n",
       "1314  17031826800  POLYGON ((-87.67975 41.64819, -87.67910 41.648...\n",
       "1315  17031710300  POLYGON ((-87.66361 41.75768, -87.66330 41.757...\n",
       "1316  17031828506  POLYGON ((-87.55864 41.54282, -87.55850 41.542...\n",
       "1317  17031825600  POLYGON ((-87.72777 41.58756, -87.72765 41.587...\n",
       "\n",
       "[1318 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapefile = gpd.read_file(\"shp/Cook_County_Tract.shp\")\n",
    "shapefile = shapefile.rename(columns={'GEOID10': 'tractID'})\n",
    "shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To see your visualization, click the URL below:\n",
      "https://cybergisx.cigi.illinois.edu/user/suhanmappingideas/view/geosnap-viz/PYTHON_Quantitative_Data_VIZ/ACM_Chicago_ACM_only/index.html\n",
      "Advanced options are available in \n",
      "https://cybergisx.cigi.illinois.edu/user/suhanmappingideas/edit/geosnap-viz/PYTHON_Quantitative_Data_VIZ/ACM_Chicago_ACM_only/data/CONFIG_Chicago_ACM_only.js\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "        'title': \"Adaptive Choropleth Mapper with Correlogram\",\n",
    "        'filename_suffix': \"Chicago_ACM_only\",\n",
    "        'inputCSV': input_attributes,   \n",
    "        'shapefile': shapefile,\n",
    "        'years': [1980, 1990, 2000, 2010],\n",
    "        'NumOfMaps': 6,\n",
    "        'variables': [\n",
    "            \"p_nonhisp_white_persons\",\n",
    "            \"p_nonhisp_black_persons\",\n",
    "            \"p_hispanic_persons\",\n",
    "            \"p_native_persons\",\n",
    "            \"p_asian_persons\",\n",
    "            \"p_hawaiian_persons\",\n",
    "            \"p_asian_indian_persons\",\n",
    "            \"p_chinese_persons\",\n",
    "            \"p_filipino_persons\",\n",
    "            \"p_japanese_persons\",\n",
    "            \"p_korean_persons\",            \n",
    "            \"p_other_language\",\n",
    "            \"p_female_headed_families\",\n",
    "            \"median_income_blackhh\",\n",
    "            \"median_income_hispanichh\",\n",
    "            \"median_income_asianhh\",\n",
    "            \"per_capita_income\",     \n",
    "        ],\n",
    "        'chart': \"Correlogram\",\n",
    "        'label': \"short_name\",        \n",
    "    }  \n",
    "Adaptive_Choropleth_Mapper_viz(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOSNAP2ACM start at 2020-10-18 15:53:05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/geosnap/_data.py:364: UserWarning: streaming remote data. Use `geosnap.io.store_census() to store the data locally for better performance\n",
      "  warn('streaming remote data. Use `geosnap.io.store_census() to store the data locally for better performance')\n",
      "/opt/conda/lib/python3.7/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To see your visualization, click the URL below:\n",
      "https://cybergisx.cigi.illinois.edu/user/suhanmappingideas/view/geosnap-viz/PYTHON_Quantitative_Data_VIZ/ACM_Chicago_ACM_only/index.html\n",
      "Advanced options are available in \n",
      "https://cybergisx.cigi.illinois.edu/user/suhanmappingideas/edit/geosnap-viz/PYTHON_Quantitative_Data_VIZ/ACM_Chicago_ACM_only/data/CONFIG_Chicago_ACM_only.js\n",
      "GEOSNAP2ACM ended at 2020-10-18 15:53:23    Elapsed 00:00:17\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import json, math, copy\n",
    "from geosnap.io import store_ltdb\n",
    "from geosnap import Community, datasets\n",
    "from geosnap.io import store_census\n",
    "import pandas as pd\n",
    "import shapely.wkt\n",
    "import shapely.geometry\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "import urllib.parse\n",
    "import webbrowser\n",
    "import os\n",
    "import pprint\n",
    "import numpy as np\n",
    "from notebook import notebookapp\n",
    "from IPython.core.display import display, HTML\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "def write_INDEX_html(param):\n",
    "    \n",
    "    #Create a new folder where CONFIG.js GEO_JSON.js VARIABLES.js will be saved\n",
    "    oDir = 'ACM_' + param['filename_suffix']\n",
    "    path = Path(oDir + '/data')\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    contents = []\n",
    "    #open Adaptive_Choropleth_Mapper.html (the excutable file for the visualization)\n",
    "    ifile = open(\"template/Adaptive_Choropleth_Mapper.html\", \"r\", encoding=\"utf-8\")\n",
    "    contents = ifile.read()\n",
    "    \n",
    "    #Replace variables based on the user's selection in each of four files below.\n",
    "    contents = contents.replace(\"Adaptive Choropleth Mapper\", param['title'])\n",
    "    contents = contents.replace(\"data/CONFIG.js\", \"data/CONFIG_\"+param['filename_suffix']+\".js\")\n",
    "    contents = contents.replace(\"data/GEO_JSON.js\", \"data/GEO_JSON_\"+param['filename_suffix']+\".js\")\n",
    "    contents = contents.replace(\"data/VARIABLES.js\", \"data/VARIABLES_\"+param['filename_suffix']+\".js\")\n",
    "    \n",
    "    #write new outfiles: CONFIG.js GEO_JSON.js VARIABLES.js\n",
    "    ofile = open(oDir+\"/index.html\", \"w\")\n",
    "    ofile.write(contents)\n",
    "    ofile.close()\n",
    "\n",
    "\n",
    "def write_CONFIG_js(param):\n",
    "    # read CONFIG.js\n",
    "    ifile = open(\"template/CONFIG.js\", \"r\", encoding=\"utf-8\")\n",
    "    contents = ifile.read()\n",
    "    \n",
    "    # Automatically identify variables for \"NumOfMaps\" and \"InitialLayers\"\n",
    "    '''when the user selects more than one year among 1970, 1980, 1990, 200 and 2010, \"NumOfMaps\" will be equal to the number of the selected years. However, when the user selects only one year among 5 years, \"NumOfMaps\" will be the number of variables that the user selected. (The maximum number of maps that can be visualized is 15) In this case, when the user selects more than 15 variables, the first 15 maps will be created at the initial view, and the rest of variables will be available in the dropdown box of the top of each map. In brief, there is no limit in terms of variables that the user can visualize, but the user can visualize upto 15 maps at the same time.'''\n",
    "    NumOfMaps = len(param['years'])\n",
    "    chart = param['chart'] if 'chart' in param else ''\n",
    "    if (chart == \"Scatter Plot\"): NumOfMaps = 2\n",
    "    InitialLayers = []\n",
    "    if (NumOfMaps > 1):\n",
    "        for i, year in enumerate(param['years']):\n",
    "            InitialLayers.append(str(year)+' '+param['labels'][0])\n",
    "    else:\n",
    "        NumOfMaps = len(param['labels'])\n",
    "        if ('NumOfMaps' in param): NumOfMaps = param['NumOfMaps']\n",
    "        if (NumOfMaps > 15): NumOfMaps = 15\n",
    "        for i, variable in enumerate(param['labels']):\n",
    "            InitialLayers.append(str(param['years'][0])+' '+variable)\n",
    "    \n",
    "    # Automatically set Map_width, Map_height. \n",
    "    Map_width = \"350px\"\n",
    "    Map_height = \"300px\"\n",
    "    if (NumOfMaps <= 5):\n",
    "        Map_width = \"400px\"\n",
    "        Map_height = \"400px\"\n",
    "    if (NumOfMaps <= 4):\n",
    "        Map_width = \"500px\"\n",
    "        Map_height = \"500px\"\n",
    "    if (NumOfMaps <= 3):\n",
    "        Map_width = \"650px\"\n",
    "        Map_height = \"650px\"\n",
    "    if (NumOfMaps <= 1):\n",
    "        Map_width = \"1000px\"\n",
    "        Map_height = \"1000px\"\n",
    "        \n",
    "    # replace newly computed \"NumOfMaps\", \"InitialLayers\", \"Map_width\", \"Map_height\" in CONFIG.js. See the example replacement below\n",
    "    '''\n",
    "        NumOfMaps  :    4                ->    'var NumOfMaps = 4;'\n",
    "        InitialLayers   :    [ … ]            ->    'var InitialLayers = [\"1980 p_nonhisp_white_persons\", \"1980 p_nonhisp_black_persons\", \"1980 p_hispanic_persons\", … ];'\n",
    "        Map_width    :    \"400px\"    ->    'var Map_width = \"400px\";'\n",
    "        Map_height   :    \"400px\"    ->    'var Map_height = \"400px\";'\n",
    "    '''\n",
    "    NumOfMaps = \"var NumOfMaps = \" + str(NumOfMaps) + \";\"\n",
    "    InitialLayers = \"var InitialLayers = \" + json.dumps(InitialLayers) + \";\"\n",
    "    Map_width = 'var Map_width  = \"' + Map_width + '\";'\n",
    "    Map_height = 'var Map_height  = \"' + Map_height + '\";'\n",
    "   \n",
    "    contents = contents.replace(\"var NumOfMaps = 1;\", NumOfMaps)\n",
    "    contents = contents.replace(\"var InitialLayers = [];\", InitialLayers)\n",
    "    contents = contents.replace('var Map_width  = \"400px\";', Map_width)\n",
    "    contents = contents.replace('var Map_height = \"400px\";', Map_height)\n",
    "    \n",
    "    chart = param['chart'] if 'chart' in param else ''\n",
    "    Stacked_Chart = \"var Stacked_Chart = false;\"\n",
    "    Correlogram = \"var Correlogram = false;\"\n",
    "    Scatter_Plot = \"var Scatter_Plot = false;\"\n",
    "    Parallel_Coordinates_Plot = \"var Parallel_Coordinates_Plot = false;\"\n",
    "    if (chart == \"Stacked Chart\"): Stacked_Chart = \"var Stacked_Chart = true;\"\n",
    "    elif (chart == \"Correlogram\"): Correlogram = \"var Correlogram = true;\"\n",
    "    elif (chart == \"Scatter Plot\"): Scatter_Plot = \"var Scatter_Plot = true;\"\n",
    "    elif (chart == \"Parallel Coordinates Plot\"): Parallel_Coordinates_Plot = \"var Parallel_Coordinates_Plot = true;\"\n",
    "    #else: Stacked_Chart = \"var Stacked_Chart = true;\"\n",
    "\n",
    "    contents = contents.replace(\"var Stacked_Chart = false;\", Stacked_Chart)\n",
    "    contents = contents.replace(\"var Correlogram = false;\", Correlogram)\n",
    "    contents = contents.replace(\"var Scatter_Plot = false;\", Scatter_Plot)\n",
    "    contents = contents.replace(\"var Parallel_Coordinates_Plot = false;\", Parallel_Coordinates_Plot)\n",
    "\n",
    "    #Write output including the replacement above\n",
    "    filename_CONFIG = \"ACM_\" + param['filename_suffix'] + \"/data/CONFIG_\"+param['filename_suffix']+\".js\"\n",
    "    ofile = open(filename_CONFIG, 'w')\n",
    "    ofile.write(contents)\n",
    "    ofile.close()\n",
    "\n",
    "\n",
    "def write_GEO_JSON_js(community, param):\n",
    "    # query geometry for each tract\n",
    "    geoid = community.gdf.columns[0]\n",
    "    tracts = community.gdf[[geoid, 'geometry']].copy()\n",
    "    tracts.drop_duplicates(subset=geoid, inplace=True)                    # get unique geoid\n",
    "    #print(tracts)\n",
    "    \n",
    "    # open GEO_JSON.js write heading for geojson format\n",
    "    filename_GEO_JSON = \"ACM_\" + param['filename_suffix'] + \"/data/GEO_JSON_\"+param['filename_suffix']+\".js\"\n",
    "    ofile = open(filename_GEO_JSON, 'w')\n",
    "    ofile.write('var GEO_JSON =\\n')\n",
    "    ofile.write('{\"type\":\"FeatureCollection\", \"features\": [\\n')\n",
    "    \n",
    "    #Convert geometry in GEOJSONP to geojson format\n",
    "    for tract in tracts.itertuples():\n",
    "        feature = {\"type\":\"Feature\"}\n",
    "        if (tract.geometry is None):                                # check is NaN?\n",
    "            #print(tract.geometry)\n",
    "            continue\n",
    "        feature[\"geometry\"] = shapely.geometry.mapping(tract.geometry)\n",
    "        #feature[\"properties\"] = {geoid: tract.__getattribute__(geoid), \"tractID\": tract.__getattribute__(geoid)}\n",
    "        feature[\"properties\"] = {geoid: tract.__getattribute__(geoid)}\n",
    "        ofile.write(json.dumps(feature)+',\\n')\n",
    "    # complete the geojosn format by adding parenthesis at the end.    \n",
    "    ofile.write(']}\\n')\n",
    "    ofile.close()\n",
    "\n",
    "\n",
    "def write_VARIABLES_js(community, param):\n",
    "    #print(param)    \n",
    "    geoid        =  community.gdf.columns[0]\n",
    "    years        =  param['years']\n",
    "    variables    =  param['variables']\n",
    "    \n",
    "    ## filtering by years\n",
    "    #community.gdf = community.gdf[community.gdf.year.isin(years)]\n",
    "    #print(community.gdf)\n",
    "    #selectedCommunity = community.gdf[variables]\n",
    "    #print(community.gdf)\n",
    "    #return\n",
    "    \n",
    "    #make heading: community.gdf.columns[0] has \"geoid\" (string)\n",
    "    heading = [geoid]\n",
    "    for i, year in enumerate(years):\n",
    "        for j, variable in enumerate(param['labels']):\n",
    "            heading.append(str(year)+' '+variable)\n",
    "    \n",
    "    #Make Dictionary\n",
    "    mydictionary = {}    # key: geoid, value: variables by heading\n",
    "    h = -1\n",
    "    selectedColumns = [geoid]\n",
    "    selectedColumns.extend(variables)\n",
    "    #print(\"selectedColumns:\", type(selectedColumns), selectedColumns)\n",
    "    for i, year in enumerate(years):\n",
    "        aYearDF = community.gdf[community.gdf.year==year][selectedColumns]\n",
    "        #print(year, type(aYearDF), aYearDF)\n",
    "        for j, variable in enumerate(variables):\n",
    "            h += 1\n",
    "            for index, row in aYearDF.iterrows():\n",
    "                #print(index, row)\n",
    "                key = row[geoid]\n",
    "                val = row[variable]\n",
    "                if (math.isnan(val)): #converts Nan in GEOSNAP data to -9999\n",
    "                    #print(i, j, key, year, val)\n",
    "                    val = -9999\n",
    "                if (key in mydictionary):\n",
    "                    value = mydictionary[key]\n",
    "                    value[h] = val\n",
    "                else:\n",
    "                    value = [-9999] * (len(heading) - 1)                \n",
    "                    value[h] = val\n",
    "                mydictionary[key] = value\n",
    "                \n",
    "    #Select keys in the Dictionary and sort\n",
    "    keys = list(mydictionary.keys())\n",
    "    keys.sort()\n",
    "    # use Keys and Dictionary created above and write them VARIABLES.js\n",
    "    filename_VARIABLES = \"ACM_\" + param['filename_suffix'] + \"/data/VARIABLES_\"+param['filename_suffix']+\".js\"\n",
    "    ofile = open(filename_VARIABLES, 'w')\n",
    "    ofile.write('var GEO_VARIABLES =\\n')\n",
    "    ofile.write('[\\n')\n",
    "    ofile.write('  '+json.dumps(heading)+',\\n')\n",
    "    for i, key in enumerate(keys):\n",
    "        values = mydictionary[key]\n",
    "        values.insert(0, key)\n",
    "        #print(key, values)\n",
    "        ofile.write('  '+json.dumps(values)+',\\n')\n",
    "    ofile.write(']\\n')\n",
    "    ofile.close()\n",
    "\n",
    "\n",
    "def Adaptive_Choropleth_Mapper_viz(param):\n",
    "    \n",
    "    # convert year, variable to years, variables in the param\n",
    "    if ('years' not in param and 'year' in param): param['years'] = [param['year']]\n",
    "    if ('variables' not in param and 'variable' in param): param['variables'] = [param['variable']]\n",
    "    #print(param)\n",
    "    \n",
    "    # select community by state_fips, msa_fips, county_fips\n",
    "    community = None\n",
    "    if ('msa_fips' in param and param['msa_fips']):\n",
    "        community = Community.from_ltdb(years=param['years'], msa_fips=param['msa_fips'])\n",
    "        #community = Community.from_ltdb(msa_fips=param['msa_fips'])\n",
    "    elif ('county_fips' in param and param['county_fips']):\n",
    "        community = Community.from_ltdb(years=param['years'], county_fips=param['county_fips'])\n",
    "    elif ('state_fips' in param and param['state_fips']):\n",
    "        community = Community.from_ltdb(years=param['years'], state_fips=param['state_fips'])\n",
    "    #print(community.gdf)\n",
    "\n",
    "# if the user enters CSV and shapefile, use the files from the user\n",
    "\n",
    "#### This is executed when the user enter attributes in csv file and geometroy in shapefile ######################  \n",
    "    if (community is None and 'inputCSV' in param):\n",
    "        community = Community()\n",
    "        #community.gdf = pd.read_csv(param['inputCSV'], dtype={'geoid':str})\n",
    "        community.gdf = param[\"inputCSV\"]\n",
    "        #print(community.gdf)\n",
    "        geoid = community.gdf.columns[0]\n",
    "        #community.gdf = community.gdf.astype(str)\n",
    "        #print(\"inputCSV:  \" + community.gdf.geoid)        \n",
    "        community.gdf[community.gdf.columns[0]] = community.gdf[geoid].astype(str)\n",
    "        #print(\"community.gdf.columns[0]:\", community.gdf.columns[0])\n",
    "        \n",
    "        # read shape file to df_shape\n",
    "        #df_shape = gpd.read_file(param['shapefile'])\n",
    "        df_shape = param['shapefile']\n",
    "        df_shape = df_shape.astype(str)     \n",
    "        #print(\"shapefile:  \" + df_shape.GEOID10)\n",
    "        geokey = df_shape.columns[0]\n",
    "        #print(geokey)    \n",
    "        df_shape = df_shape.set_index(geokey)\n",
    "        \n",
    "        # insert geometry to community.gdf\n",
    "        geometry = []\n",
    "        for index, row in community.gdf.iterrows():\n",
    "            tractid = row[geoid]\n",
    "            try:\n",
    "                tract = df_shape.loc[tractid]\n",
    "                geometry.append(shapely.wkt.loads(tract.geometry))\n",
    "            except KeyError:\n",
    "                #print(\"Tract ID [{}] is not found in the shape file {}\".format(tractid, param['shapefile']))\n",
    "                geometry.append(None)\n",
    "        community.gdf.insert(len(community.gdf.columns), \"geometry\", geometry)\n",
    "################################################################################################################      \n",
    "    \n",
    "    community.gdf = community.gdf.replace([np.inf, -np.inf], np.nan)\n",
    "    # check if geometry is not null for Spatial Clustering\n",
    "    community.gdf = community.gdf[pd.notnull(community.gdf['geometry'])]\n",
    "    #print(community.gdf)\n",
    "    community.gdf.to_csv('output_temp.csv')\n",
    "    \n",
    "    codebook = pd.read_csv('template/conversion_table_codebook.csv')\n",
    "    codebook.set_index(keys='variable', inplace=True)\n",
    "    labels = copy.deepcopy(param['variables'])\n",
    "    label = 'short_name'                                             # default\n",
    "    if (param['label'] == 'variable'): label = 'variable'\n",
    "    if (param['label'] == 'full_name'): label = 'full_name'\n",
    "    if (param['label'] == 'short_name'): label = 'short_name'\n",
    "    if (label != 'variable'):\n",
    "        for idx, variable in enumerate(param['variables']):\n",
    "            try:\n",
    "                codeRec = codebook.loc[variable]\n",
    "                labels[idx] = codeRec[label]\n",
    "            except:\n",
    "                print(\"variable not found in codebook.  variable:\", variable)\n",
    "    param['labels'] = labels\n",
    "    \n",
    "    write_INDEX_html(param)\n",
    "    write_CONFIG_js(param)\n",
    "    write_VARIABLES_js(community, param)\n",
    "    write_GEO_JSON_js(community, param)\n",
    "    \n",
    "    '''\n",
    "    #Create directory for local machine\n",
    "    local_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "    fname =urllib.parse.quote('index.html')\n",
    "    template_dir = os.path.join(local_dir, 'ACM_' + param['filename_suffix'])\n",
    "    url = 'file:' + os.path.join(template_dir, fname)\n",
    "    webbrowser.open(url)\n",
    "    \n",
    "    print('Please run ' + '\"ACM_' + param['filename_suffix']+'/index.html\"'+' to your web browser.')\n",
    "    print('Advanced options are available in ' + '\"ACM_' + param['filename_suffix']+'/data/CONFIG.js\"')\n",
    "    '''\n",
    "\n",
    "    #Create directory for VIZ in CyberGISX    \n",
    "    servers = list(notebookapp.list_running_servers())\n",
    "    servers1 = 'https://cybergisx.cigi.illinois.edu'+servers[0][\"base_url\"]+ 'view'\n",
    "    servers2 = 'https://cybergisx.cigi.illinois.edu'+servers[0][\"base_url\"]+ 'edit'      \n",
    "    cwd = os.getcwd()\n",
    "    prefix_cwd = \"/home/jovyan/work\"\n",
    "    cwd = cwd.replace(prefix_cwd, \"\")\n",
    "    local_dir1 = servers1 + cwd\n",
    "    local_dir2 = servers2 + cwd    \n",
    "    #print(local_dir)\n",
    "    fname =urllib.parse.quote('index.html')\n",
    "    template_dir = os.path.join(local_dir1, 'ACM_' + param['filename_suffix'])\n",
    "    #url = 'file:' + os.path.join(template_dir, fname)\n",
    "    url = os.path.join(template_dir, fname)    \n",
    "    webbrowser.open(url)\n",
    "    print('To see your visualization, click the URL below:')\n",
    "    print(url)    \n",
    "    print('Advanced options are available in ')  \n",
    "    print(local_dir2 + '/'+ 'ACM_' + param['filename_suffix']+'/data/CONFIG_' + param['filename_suffix']+'.js')       \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    started_datetime = datetime.now()\n",
    "    dateYYMMDD = started_datetime.strftime('%Y%m%d')\n",
    "    timeHHMMSS = started_datetime.strftime('%H%M%S')\n",
    "    print('GEOSNAP2ACM start at %s %s' % (started_datetime.strftime('%Y-%m-%d'), started_datetime.strftime('%H:%M:%S')))\n",
    "    \n",
    "    #sample = \"downloads/LTDB_Std_All_Sample.zip\"\n",
    "    #full = \"downloads/LTDB_Std_All_fullcount.zip\"\n",
    "    #store_ltdb(sample=sample, fullcount=full)\n",
    "    #store_census()\n",
    "    #geosnap.io.store_census()\n",
    "    \n",
    "    param2 = {\n",
    "            'title': \"Adaptive Choropleth Mapper\",\n",
    "            'filename_suffix': \"Chicago_ACM_only\",\n",
    "            'state_fips': None,      #fips code is avaiable for every US state at https://github.com/suhanmappingideas/geosnap-viz/blob/master/state_id.csv\n",
    "            'msa_fips': None,         #For more options: http://su-gis.iptime.org/LNE/pick_POI.html\n",
    "            'county_fips': \"17031\",   #county code is also availabe in the link right above. \n",
    "            'years': [1980, 1990, 2000, 2010],\n",
    "            'variables': [\n",
    "                \"p_nonhisp_white_persons\",\n",
    "                \"p_nonhisp_black_persons\",\n",
    "                \"p_hispanic_persons\",\n",
    "                \"p_native_persons\",\n",
    "                \"p_asian_persons\",\n",
    "                \"p_hawaiian_persons\",\n",
    "                \"p_asian_indian_persons\",\n",
    "                \"p_chinese_persons\",\n",
    "                \"p_filipino_persons\",\n",
    "                \"p_japanese_persons\",\n",
    "                \"p_korean_persons\",           \n",
    "            ],\n",
    "            'label': \"short_name\",                                       # variable, short_name or full_name\n",
    "            #'chart': \"Stacked Chart\",    \n",
    "            #'chart': \"Correlogram\",\n",
    "            #'chart': \"Scatter Plot\",   \n",
    "            #'chart': \"Parallel Coordinates Plot\",    \n",
    "    }\n",
    "    input_attributes = pd.read_csv(\"attributes/Copy of San_Diego_ACS_2010.csv\", dtype={'geoid':str})\n",
    "    shapefile = gpd.read_file(\"shp/San_Diego2010.shp\")\n",
    "\n",
    "    param = {\n",
    "            'title': \"Adaptive Choropleth Mapper with Correlogram\",\n",
    "            'filename_suffix': \"SD_correlogram_from_csv\",\n",
    "            'inputCSV': input_attributes,   \n",
    "            'shapefile': shapefile,\n",
    "            'year': 2000,\n",
    "            'NumOfMaps': 6,\n",
    "            'variables': [\n",
    "                \"p_other_language\",\n",
    "                \"p_female_headed_families\",\n",
    "                \"median_income_blackhh\",\n",
    "                \"median_income_hispanichh\",\n",
    "                \"median_income_asianhh\",\n",
    "                \"per_capita_income\",     \n",
    "            ],\n",
    "            'chart': \"Correlogram\",\n",
    "            'label': \"short_name\",        \n",
    "    }\n",
    "    \n",
    "    Adaptive_Choropleth_Mapper_viz(param2)\n",
    "    \n",
    "    ended_datetime = datetime.now()\n",
    "    elapsed = ended_datetime - started_datetime\n",
    "    total_seconds = int(elapsed.total_seconds())\n",
    "    hours, remainder = divmod(total_seconds,60*60)\n",
    "    minutes, seconds = divmod(remainder,60)    \n",
    "    print('GEOSNAP2ACM ended at %s %s    Elapsed %02d:%02d:%02d' % (ended_datetime.strftime('%Y-%m-%d'), ended_datetime.strftime('%H:%M:%S'), hours, minutes, seconds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
