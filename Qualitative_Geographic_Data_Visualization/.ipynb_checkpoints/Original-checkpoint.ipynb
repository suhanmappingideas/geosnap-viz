{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOSNAP2NAM start at 2020-10-03 18:01:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading manifest: 100%|██████████| 5/5 [00:00<00:00, 6521.00entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed package 'census/tracts_cartographic', tophash=476770c from s3://spatial-ucr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading manifest: 100%|██████████| 5/5 [00:00<00:00, 8345.21entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed package 'census/administrative', tophash=0616d02 from s3://spatial-ucr\n",
      "GEOSNAP2NAM ended at 2020-10-03 18:01:42    Elapsed 00:00:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import json, math, copy, sys\n",
    "from geosnap.io import store_ltdb\n",
    "from geosnap import Community, datasets\n",
    "from geosnap.io import store_census\n",
    "\n",
    "import pandas as pd\n",
    "import shapely.wkt\n",
    "import shapely.geometry\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "from INCS import linc\n",
    "import urllib.parse\n",
    "import webbrowser\n",
    "import os\n",
    "import pprint\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from notebook import notebookapp\n",
    "\n",
    "\n",
    "def write_LOG(param):\n",
    "\t#Create a new folder where GEO_CONFIG.js GEO_JSON.js VARIABLES.js will be saved\n",
    "\toDir = 'NAM_' + param['filename_suffix']\n",
    "\tpath = Path(oDir + '/data')\n",
    "\tpath.mkdir(parents=True, exist_ok=True)\n",
    "\t\n",
    "\tcontents = pprint.pformat(param)\n",
    "\t#print(oDir+\"/data/param.log\")\n",
    "\t#print(contents)\n",
    "\t#write new outfiles: GEO_CONFIG.js GEO_JSON.js VARIABLES.js\n",
    "\tofile = open(oDir+\"/data/param.log\", \"w\")\n",
    "\tcreate_at = datetime.now()\n",
    "\tofile.write('%s %s\\r\\n' % (create_at.strftime('%Y-%m-%d'), create_at.strftime('%H:%M:%S')))\n",
    "\t#ofile.write('\\r\\n\\r\\n')\n",
    "\tofile.write('  '+contents.replace('\\n', '\\n  '))\n",
    "\tofile.close()\n",
    "\n",
    "\n",
    "def write_INDEX_html(param):\n",
    "\t#Create a new folder where GEO_CONFIG.js GEO_JSON.js VARIABLES.js will be saved\n",
    "\toDir = 'NAM_' + param['filename_suffix']\n",
    "\tpath = Path(oDir + '/data')\n",
    "\tpath.mkdir(parents=True, exist_ok=True)\n",
    "\t\n",
    "\tcontents = []\n",
    "\t#open Neighborhood_Analysis_Mapper.html (the excutable file for the visualization)\n",
    "\tifile = open(\"template/Neighborhood_Analysis_Mapper.html\", \"r\", encoding=\"utf-8\")\n",
    "\tcontents = ifile.read()\n",
    "\t\n",
    "\t#Replace variables based on the user's selection in each of four files below.\n",
    "\tcontents = contents.replace(\"Neighborhood Analysis Mapper\", param['title'])\n",
    "\tcontents = contents.replace(\"data/GEO_CONFIG.js\", \"data/GEO_CONFIG_\"+param['filename_suffix']+\".js\")\n",
    "\tcontents = contents.replace(\"data/GEO_JSON.js\", \"data/GEO_JSON_\"+param['filename_suffix']+\".js\")\n",
    "\tcontents = contents.replace(\"data/GEO_VARIABLES.js\", \"data/GEO_VARIABLES_\"+param['filename_suffix']+\".js\")\n",
    "\t\n",
    "\t#write new outfiles: GEO_CONFIG.js GEO_JSON.js VARIABLES.js\n",
    "\tofile = open(oDir+\"/index.html\", \"w\", encoding=\"utf-8\")\n",
    "\tofile.write(contents)\n",
    "\tofile.close()\n",
    "\n",
    "def write_GEO_CONFIG_js(param):\n",
    "\t# read ACM_GEO_CONFIG.js\n",
    "\tifile = open(\"template/NAM_GEO_CONFIG.js\", \"r\", encoding=\"utf-8\")\n",
    "\tcontents = ifile.read()\n",
    "\t\n",
    "\tallMetros = False;\n",
    "\tIndex_of_neighborhood_change = True;\n",
    "\tMaps_of_neighborhood = True;               \n",
    "\tDistribution_INC1 = True;                  \n",
    "\tDistribution_period = False; \n",
    "\tDistribution_cluster = False;\n",
    "\tTemporal_change_in_neighborhoods = True;\n",
    "\tParallel_Categories_Diagram_in_neighborhoods = True;\n",
    "\tChord_Diagram_in_neighborhoods = True;\n",
    "\tZscore_Means_across_Clusters = True;\n",
    "\tZscore_Means_of_Each_Cluster = True;\n",
    "\t\n",
    "\tif ('allMetros' in param): allMetros =  param['allMetros']\n",
    "\tif ('Index_of_neighborhood_change' in param): Index_of_neighborhood_change =  param['Index_of_neighborhood_change']\n",
    "\tif ('Maps_of_neighborhood' in param): Maps_of_neighborhood =  param['Maps_of_neighborhood']\n",
    "\tif ('Distribution_INC1' in param): Distribution_INC1 =  param['Distribution_INC1']\n",
    "\tif ('Distribution_INC2_different_period' in param): Distribution_period =  param['Distribution_INC2_different_period']\n",
    "\tif ('Distribution_INC2_different_cluster' in param): Distribution_cluster =  param['Distribution_INC2_different_cluster']\n",
    "\tif ('Temporal_change_in_neighborhoods' in param): Temporal_change_in_neighborhoods =  param['Temporal_change_in_neighborhoods']\n",
    "\tif ('Parallel_Categories_Diagram_in_neighborhoods' in param): Parallel_Categories_Diagram_in_neighborhoods =  param['Parallel_Categories_Diagram_in_neighborhoods']\n",
    "\tif ('Chord_Diagram_in_neighborhoods' in param): Chord_Diagram_in_neighborhoods =  param['Chord_Diagram_in_neighborhoods']\n",
    "\tif ('Zscore_Means_across_Clusters' in param): Zscore_Means_across_Clusters =  param['Zscore_Means_across_Clusters']\n",
    "\tif ('Zscore_Means_of_Each_Cluster' in param): Zscore_Means_of_Each_Cluster =  param['Zscore_Means_of_Each_Cluster']\n",
    "\t\n",
    "\t# perpare parameters\n",
    "\t#NumOfMaps = len(param['years']) + 1\n",
    "\tNumOfMaps = len(param['years']) + 1 if Index_of_neighborhood_change else len(param['years'])\n",
    "\t#InitialLayers = [\"INC\"]\n",
    "\tInitialLayers = [\"INC\"] if Index_of_neighborhood_change else []\n",
    "\tif (len(param['years']) <= 1): InitialLayers = []\n",
    "\tfor i, year in enumerate(param['years']):\n",
    "\t\tInitialLayers.append(str(year))\n",
    "\t\n",
    "\t# Automatically set Map_width, Map_height. \n",
    "\tMap_width = \"300px\"\n",
    "\tMap_height = \"300px\"\n",
    "\tif (NumOfMaps <= 6):\n",
    "\t\tMap_width = \"300px\"\n",
    "\t\tMap_height = \"300px\"\t\n",
    "\tif (NumOfMaps <= 5):\n",
    "\t\tMap_width = \"350px\"\n",
    "\t\tMap_height = \"350px\"\n",
    "\tif (NumOfMaps <= 4):\n",
    "\t\tMap_width = \"400px\"\n",
    "\t\tMap_height = \"400px\"\n",
    "\tif (NumOfMaps <= 3):\n",
    "\t\tMap_width = \"400px\"\n",
    "\t\tMap_height = \"400px\"\n",
    "\tif (NumOfMaps <= 2):\n",
    "\t\tMap_width = \"450px\"\n",
    "\t\tMap_height = \"450px\"\n",
    "\tif (NumOfMaps ==\t1):\n",
    "\t\tMap_width = \"800px\"\n",
    "\t\tMap_height = \"800px\"\t\n",
    "\t# replace newly computed \"NumOfMaps\", \"InitialLayers\", \"Map_width\", \"Map_height\" in CONFIG.js. See the example replacement below\n",
    "\t'''\n",
    "\t\t'years': [1980, 1990, 2000, 2010]            ->    'var InitialLayers = [\"INC\", \"1980\", \"1990\", \"2000\", \"2010\"];'\n",
    "\t'''\n",
    "\tNumOfMaps = \"var NumOfMaps = \" + str(NumOfMaps) + \";\"\n",
    "\tInitialLayers = \"var InitialLayers = \" + json.dumps(InitialLayers) + \";\"\n",
    "\tallMetros = \"var allMetros = \" + json.dumps(allMetros)+ \";\"\n",
    "\tIndex_of_neighborhood_change = \"var Index_of_neighborhood_change = \" + json.dumps(Index_of_neighborhood_change)+ \";\"\n",
    "\tMaps_of_neighborhood = \"var Maps_of_neighborhood = \" + json.dumps(Maps_of_neighborhood)+ \";\"\n",
    "\tDistribution_INC1 = \"var Distribution_INC1 = \" + json.dumps(Distribution_INC1)+ \";\"\n",
    "\tDistribution_period = \"var Distribution_INC2_different_period = \" + json.dumps(Distribution_period)+ \";\"\n",
    "\tDistribution_cluster = \"var Distribution_INC2_different_cluster = \" + json.dumps(Distribution_cluster)+ \";\"\n",
    "\tTemporal_change_in_neighborhoods = \"var Temporal_change_in_neighborhoods = \" + json.dumps(Temporal_change_in_neighborhoods)+ \";\"\n",
    "\tParallel_Categories_Diagram_in_neighborhoods = \"var Parallel_Categories_Diagram_in_neighborhoods = \" + json.dumps(Parallel_Categories_Diagram_in_neighborhoods)+ \";\"\n",
    "\tChord_Diagram_in_neighborhoods = \"var Chord_Diagram_in_neighborhoods = \" + json.dumps(Chord_Diagram_in_neighborhoods)+ \";\"\n",
    "\tZscore_Means_across_Clusters = \"var Zscore_Means_across_Clusters = \" + json.dumps(Zscore_Means_across_Clusters)+ \";\"\n",
    "\tZscore_Means_of_Each_Cluster = \"var Zscore_Means_of_Each_Cluster = \" + json.dumps(Zscore_Means_of_Each_Cluster)+ \";\"\n",
    "\tMap_width = 'var Map_width  = \"' + Map_width + '\";'\n",
    "\tMap_height = 'var Map_height = \"' + Map_height + '\";'\n",
    "   \n",
    "\tcontents = contents.replace(\"var InitialLayers = [];\", InitialLayers)\n",
    "\tcontents = contents.replace(\"var allMetros = false;\", allMetros)\n",
    "\tcontents = contents.replace(\"var Index_of_neighborhood_change = true;\", Index_of_neighborhood_change)\n",
    "\tcontents = contents.replace(\"var Maps_of_neighborhood = true;\", Maps_of_neighborhood)\n",
    "\tcontents = contents.replace(\"var Distribution_INC1 = true;\", Distribution_INC1)\n",
    "\tcontents = contents.replace(\"var Distribution_INC2_different_period = true;\", Distribution_period)\n",
    "\tcontents = contents.replace(\"var Distribution_INC2_different_cluster = true;\", Distribution_cluster)\n",
    "\tcontents = contents.replace(\"var Temporal_change_in_neighborhoods = true;\", Temporal_change_in_neighborhoods)\n",
    "\tcontents = contents.replace(\"var Parallel_Categories_Diagram_in_neighborhoods = true;\", Parallel_Categories_Diagram_in_neighborhoods)\n",
    "\tcontents = contents.replace(\"var Chord_Diagram_in_neighborhoods = true;\", Chord_Diagram_in_neighborhoods)\n",
    "\tcontents = contents.replace(\"var Zscore_Means_across_Clusters = true;\", Zscore_Means_across_Clusters)\n",
    "\tcontents = contents.replace(\"var Zscore_Means_of_Each_Cluster = true;\", Zscore_Means_of_Each_Cluster)\n",
    "\tcontents = contents.replace('var Map_width  = \"400px\";', Map_width)\n",
    "\tcontents = contents.replace('var Map_height = \"400px\";', Map_height)\n",
    "\n",
    "\t#Write output including the replacement above\n",
    "\tfilename_GEO_CONFIG = \"NAM_\" + param['filename_suffix'] + \"/data/GEO_CONFIG_\"+param['filename_suffix']+\".js\"\n",
    "\tofile = open(filename_GEO_CONFIG, 'w', encoding=\"utf-8\")\n",
    "\tofile.write(contents)\n",
    "\tofile.close()\n",
    "\n",
    "\n",
    "def write_ALL_METROS_GEO_CONFIG_js(param):\n",
    "\t# read GEO_CONFIG.js\n",
    "\tifile = open(\"template/ACM_GEO_CONFIG.js\", \"r\", encoding=\"utf-8\")\n",
    "\tcontents = ifile.read()\n",
    "\t\n",
    "\tStacked_Chart = False;\n",
    "\tCorrelogram = False;\n",
    "\tScatter_Plot = False;               \n",
    "\tParallel_Coordinates_Plot = False;                  \n",
    "\t\n",
    "\t# perpare parameters\n",
    "\tNumOfMaps = 1\n",
    "\tInitialLayers = [\"INC\"]\n",
    "\t\n",
    "\t# Automatically set Map_width, Map_height. \n",
    "\tMap_width = \"1400px\"\n",
    "\tMap_height = \"800px\"\n",
    "\t\n",
    "\t# replace newly computed \"NumOfMaps\", \"InitialLayers\", \"Map_width\", \"Map_height\" in CONFIG.js. See the example replacement below\n",
    "\tNumOfMaps = \"var NumOfMaps = \" + str(NumOfMaps) + \";\"\n",
    "\tInitialLayers = \"var InitialLayers = \" + json.dumps(InitialLayers) + \";\"\n",
    "\tInitial_map_center = \"var Initial_map_center = [37, -98.5795];\"\n",
    "\tInitial_map_zoom_level = \"var Initial_map_zoom_level = 5;\"\n",
    "\tMap_width = 'var Map_width  = \"' + Map_width + '\";'\n",
    "\tMap_height = 'var Map_height = \"' + Map_height + '\";'\n",
    "   \n",
    "\tcontents = contents.replace(\"var NumOfMaps = 1;\", NumOfMaps)\n",
    "\tcontents = contents.replace(\"var InitialLayers = [];\", InitialLayers)\n",
    "\tcontents = contents.replace(\"//var Initial_map_center = [34.0522, -117.9];\", Initial_map_center)\n",
    "\tcontents = contents.replace(\"//var Initial_map_zoom_level = 8;\", Initial_map_zoom_level)\n",
    "\tcontents = contents.replace('var Map_width  = \"400px\";', Map_width)\n",
    "\tcontents = contents.replace('var Map_height = \"400px\";', Map_height)\n",
    "\n",
    "\t#Write output including the replacement above\n",
    "\tfilename_GEO_CONFIG = \"NAM_\" + param['filename_suffix'] + \"/data/GEO_CONFIG_\"+param['filename_suffix']+\".js\"\n",
    "\tofile = open(filename_GEO_CONFIG, 'w', encoding=\"utf-8\")\n",
    "\tofile.write(contents)\n",
    "\tofile.close()\n",
    "\n",
    "def write_GEO_JSON_js(community, param):\n",
    "\t# query geometry for each tract\n",
    "\tgeoid = community.gdf.columns[0]\n",
    "\ttracts = community.gdf[[geoid, 'geometry']].copy()\n",
    "\ttracts.drop_duplicates(subset=geoid, inplace=True)\t\t\t\t\t# get unique geoid\n",
    "\t#print(tracts)\n",
    "\t\n",
    "\t# open GEO_JSON.js write heading for geojson format\n",
    "\tfilename_GEO_JSON = \"NAM_\" + param['filename_suffix'] + \"/data/GEO_JSON_\"+param['filename_suffix']+\".js\"\n",
    "\tofile = open(filename_GEO_JSON, 'w')\n",
    "\tofile.write('var GEO_JSON =\\n')\n",
    "\tofile.write('{\"type\":\"FeatureCollection\", \"features\": [\\n')\n",
    "\t\n",
    "\t#Convert geometry in GEOJSONP to geojson format\n",
    "\twCount = 0\n",
    "\tfor tract in tracts.itertuples():\n",
    "\t\tfeature = {\"type\":\"Feature\"}\n",
    "\t\tif (type(tract.geometry) is float):\t\t\t\t\t\t\t\t# check is NaN?\n",
    "\t\t\t#print(tract.geometry)\n",
    "\t\t\tcontinue\n",
    "\t\tfeature[\"geometry\"] = shapely.geometry.mapping(tract.geometry)\n",
    "\t\t#feature[\"properties\"] = {geoid: tract.__getattribute__(geoid), \"tractID\": tract.__getattribute__(geoid)}\n",
    "\t\tfeature[\"properties\"] = {geoid: tract.__getattribute__(geoid)}\n",
    "\t\twCount += 1\n",
    "\t\tofile.write(json.dumps(feature)+',\\n')\n",
    "\t#print(\"GEO_JSON.js write count:\", wCount)\n",
    "\t# complete the geojosn format by adding parenthesis at the end.\t\n",
    "\tofile.write(']}\\n')\n",
    "\tofile.close()\n",
    "\n",
    "def write_GEO_VARIABLES_js(community, param):\n",
    "\t#print(param)\n",
    "\tgeoid       = community.gdf.columns[0]\n",
    "\tmethod      = param['method']\n",
    "\tnClusters   = param['nClusters']\n",
    "\tyears       = param['years']\n",
    "\tvariables   = param['variables']\n",
    "\tlabels      = param['labels']\n",
    "\t\n",
    "\tseqClusters = 5\n",
    "\tdistType    = 'tran'\n",
    "\tif ('Sequence' in param and type(param['Sequence']) is dict):\n",
    "\t\tif ('seq_clusters' in param['Sequence']): seqClusters = param['Sequence']['seq_clusters']\n",
    "\t\tif ('dist_type' in param['Sequence']): distType = param['Sequence']['dist_type']\n",
    "\t\n",
    "\t# filtering by years\n",
    "\tcommunity.gdf = community.gdf[community.gdf.year.isin(years)]\n",
    "\t#print(community.gdf)\n",
    "\tcommunity.gdf.to_csv(r'output.csv')    \n",
    "\n",
    "\tif (method == 'kmeans' or method == 'ward' or method == 'affinity_propagation' or method == 'spectral' or method == 'gaussian_mixture' or method == 'hdbscan'):\n",
    "\t\tclusters = community.cluster(columns=variables, method=method, n_clusters=nClusters)\n",
    "\tif (method == 'ward_spatial' or method == 'spenc' or method == 'skater' or method == 'azp' or method == 'max_p'):\n",
    "\t\tclusters = community.cluster_spatial(columns=variables, method=method, n_clusters=nClusters)\t\t\n",
    "\n",
    "\t# Use the sequence method to obtain the distance matrix of neighborhood sequences\n",
    "\tgdf_new, df_wide, seq_dis_mat = clusters.sequence(seq_clusters=seqClusters, dist_type=distType, cluster_col=method)\n",
    "\t#print(df_wide)\n",
    "\t\n",
    "\t# pivot by year column\n",
    "\t#df_pivot = df.reset_index().pivot(geoid, \"year\", method)\n",
    "\tdf_pivot = df_wide\n",
    "\tlastColumn = df_pivot.columns[df_pivot.shape[1]-1]\t\t\t\t\t# get the last column name as like 'tran-5'\n",
    "\tdf_pivot.rename(columns={lastColumn: 'Sequence'}, inplace=True)\t\t# change the last column name to 'Sequence'\n",
    "\t#print(df_pivot)\n",
    "'''\n",
    "\tif (len(years) > 1):\n",
    "\t\t# convert df_pivot to list for INCS.linc\n",
    "\t\tyearList = []\n",
    "\t\t#for year in df_pivot.columns:\n",
    "\t\tfor year in years:\n",
    "\t\t\taYearList = df_pivot[year].values.tolist()\n",
    "\t\t\taYearList = list(map(float, aYearList)) \n",
    "\t\t\tyearList.append(aYearList)\n",
    "\t\t#print(yearList)\n",
    "\t\t# calculate INC\n",
    "\t\tincs = linc(yearList)\n",
    "\t\t#print(incs)\n",
    "\t\t#incs = minmax_scale(incs, feature_range=(0,1), axis=0)\n",
    "\t\t#print(incs)\t\t\n",
    "\t\t# insert INC to first column of df_pivot\n",
    "\t\tdf_pivot.insert(loc=0, column='INC', value=incs)\n",
    "'''\n",
    "\tif ('Sequence' not in param or not param['Sequence']): df_pivot.drop(columns=['Sequence'], inplace=True)\n",
    "\t#if ('Sequence' not in param or type(param['Sequence']) is not dict): df_pivot.drop(columns=['Sequence'], inplace=True)\n",
    "\t#print(df_pivot)\n",
    "\t\n",
    "\t# calculate zscore\n",
    "\tclusters_flattened = pd.DataFrame(df_pivot.to_records())                   # convert pivot to data frame\n",
    "\tgeoids = clusters_flattened[\"geoid\"].tolist()                              # get list of geoids from pivot\n",
    "\tvalid_gdf = community.gdf[community.gdf.geoid.isin(geoids)]                # get all rows of valid geoids from community.gdf\n",
    "\t#print(\"clusters_flattened:\", clusters_flattened)\n",
    "\t#print(\"geoids: \", len(geoids))\n",
    "\t#print(\"geoids:\", geoids)\n",
    "\t#print(\"valid_gdf:\", valid_gdf)\n",
    "\t\n",
    "\tlastClusterNo = 0\n",
    "\tfor y, year in enumerate(years):\n",
    "\t\tmaxClusterNo_theYear = clusters_flattened[str(year)].max()\n",
    "\t\tif (lastClusterNo < maxClusterNo_theYear): \n",
    "\t\t\tlastClusterNo = maxClusterNo_theYear\n",
    "\t#print(\"lastClusterNo:\", lastClusterNo)\n",
    "\tnGeneratedClusters = lastClusterNo + 1\n",
    "\t\n",
    "\t# get sum of the each cluster and count of the each cluster\n",
    "\tzValue = [[0 for v in range(len(variables))] for c in range(nGeneratedClusters)]\n",
    "\tzCount = [[0 for v in range(len(variables))] for c in range(nGeneratedClusters)]\n",
    "\tfor v, variable in enumerate(variables):\n",
    "\t\t#if (v > 0): break\n",
    "\t\ttheVariable_pivot = valid_gdf.pivot(index='geoid', columns='year', values=variable)\n",
    "\t\ttheVariable_flattened = pd.DataFrame(theVariable_pivot.to_records())   # convert pivot to data frame\n",
    "\t\t#print(theVariable_pivot)\n",
    "\t\t#print(\"theVariable_flattened: \", variable)\n",
    "\t\t#print(theVariable_flattened)\n",
    "\t\tif (theVariable_flattened.shape[0] != len(geoids)):                    # check number of pivot and valid geoids\n",
    "\t\t\tprint(\"Number of valid geoid not equal pivot of '\" + variable +\"'\")\n",
    "\t\t\tprint(\"Number of geoids: \", len(geoids))\n",
    "\t\t\tprint(\"Number of pivot : \", theVariable_flattened.shape[0])\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\t# make a variable list of all years from pivot\n",
    "\t\ttheVariableList = np.array([])\n",
    "\t\tfor y, year in enumerate(years):\n",
    "\t\t\ttheYearList = theVariable_flattened[str(year)].tolist()\n",
    "\t\t\ttheVariableList = np.append(theVariableList, theYearList)\n",
    "\t\t#print(\"theVariableList: \", theVariableList.shape[0], theVariableList)\n",
    "\t\t\n",
    "\t\ttheVariableZscore = stats.zscore(theVariableList)                      # calculate zscore\n",
    "\t\t#print(\"theVariableZscore: \", theVariableZscore.shape[0], theVariableZscore)\n",
    "\t\t\n",
    "\t\tfor y, year in enumerate(years):\n",
    "\t\t\ti = y * clusters_flattened.shape[0]\n",
    "\t\t\tfor j, row in clusters_flattened.iterrows():\n",
    "\t\t\t\tcluster = row[str(year)]\n",
    "\t\t\t\t#print(\"zValue[%d][%d] += theVariableZscore[%d]\" % (cluster, v, i+j))\n",
    "\t\t\t\tzValue[cluster][v] += theVariableZscore[i+j]                   # accumulate zscore to the position of cluster\n",
    "\t\t\t\tzCount[cluster][v] += 1                                        # count up by 1 to the position of cluster\n",
    "\t#print(zValue)\n",
    "\t#print(zCount)\n",
    "\t\n",
    "\t# calculate average of zscore\n",
    "\tzScore = [[0 for v in range(len(variables))] for c in range(nGeneratedClusters)]\n",
    "\tfor v, variable in enumerate(variables):\n",
    "\t\tfor c in range(nGeneratedClusters):\n",
    "\t\t\tif (zCount[c][v] != 0): zScore[c][v] = round(zValue[c][v] / zCount[c][v], 2)\n",
    "\t#print(zScore)\n",
    "\n",
    "\t# write df_pivot to GEO_VARIABLES.js\n",
    "\tfilename_GEO_VARIABLES = \"NAM_\" + param['filename_suffix'] + \"/data/GEO_VARIABLES_\"+param['filename_suffix']+\".js\"\n",
    "\tofile = open(filename_GEO_VARIABLES, 'w')\n",
    "\tofile.write('var GEO_VARIABLES =\\n')\n",
    "\tofile.write('[\\n')\n",
    "\t#heading = [geoid, 'INC']\n",
    "\t#if (len(years) <= 1): heading = [geoid]\n",
    "\t#heading.extend(list(map(str, years)))\n",
    "\theading = [geoid]\n",
    "\theading.extend(list(map(str, df_pivot.columns.tolist())))\n",
    "\tofile.write('  '+json.dumps(heading)+',\\n')\n",
    "\twCount = 0\n",
    "\tfor i, row in df_pivot.reset_index().iterrows():\n",
    "\t\taLine = row.tolist()\n",
    "\t\tfor j, col in enumerate(aLine[2:], 2):\n",
    "\t\t\ttry:\n",
    "\t\t\t\taLine[j] = int(col)                                  # convert float to int\n",
    "\t\t\texcept ValueError:\n",
    "\t\t\t\taLine[j] = -9999                                     # if Nan, set -9999\n",
    "\t\twCount += 1 \n",
    "\t\tofile.write('  '+json.dumps(aLine)+',\\n')\n",
    "\t#print(\"GEO_VARIABLES.js write count:\", wCount)\n",
    "\tofile.write(']\\n')\n",
    "\t\n",
    "\t# write zscore to GEO_VARIABLES.js\n",
    "\tofile.write('\\n')\n",
    "\tofile.write('var GEO_ZSCORES =\\n')\n",
    "\tofile.write('{\\n')\n",
    "\tofile.write('  \"xAxis\": [\\n')\n",
    "\tfor v, variable in enumerate(labels):\n",
    "\t\tofile.write('    \"'+variable+'\",\\n')\n",
    "\tofile.write('  ],\\n')\n",
    "\tofile.write('  \"yAxis\": '+json.dumps([\"C\"+str(c) for c in range(nGeneratedClusters)])+',\\n')\n",
    "\tofile.write('  \"data\" : [\\n')\n",
    "\tfor z, row in enumerate(zScore):\n",
    "\t\tofile.write('    '+json.dumps(row)+',\\n')\n",
    "\tofile.write('  ],\\n')\n",
    "\tofile.write('}\\n')\n",
    "\n",
    "\tofile.close()\n",
    "\n",
    "def Clustering_viz(param):\n",
    "\twrite_LOG(param)\n",
    "\t\n",
    "\t# select community by state_fips, msa_fips, county_fips\n",
    "\tmetros = None\n",
    "\tcommunity = None\n",
    "\tif ('allMetros' in param and param['allMetros']):\n",
    "\t\t#metros = data_store.msa_definitions\n",
    "\t\t#print(metros)\n",
    "\t\t#metros = data_store.msas()\n",
    "\t\tmetros = datasets.msas()\n",
    "\telif ('msa_fips' in param and param['msa_fips']):\n",
    "\t\tcommunity = Community.from_ltdb(years=param['years'], msa_fips=param['msa_fips'])\n",
    "\t\t#community = Community.from_ltdb(msa_fips=param['msa_fips'])\n",
    "\telif ('county_fips' in param and param['county_fips']):\n",
    "\t\tcommunity = Community.from_ltdb(years=param['years'], county_fips=param['county_fips'])\n",
    "\telif ('state_fips' in param and param['state_fips']):\n",
    "\t\tcommunity = Community.from_ltdb(years=param['years'], state_fips=param['state_fips'])\n",
    "\t\n",
    "\tcommunity.gdf = community.gdf.replace([np.inf, -np.inf], np.nan)\n",
    "\t\n",
    "\t# check if geometry is not null for Spatial Clustering\n",
    "\tcommunity.gdf = community.gdf[pd.notnull(community.gdf['geometry'])]\n",
    "\t#print(community.gdf)\n",
    "    \n",
    "\tcodebook = pd.read_csv('template/conversion_table_codebook.csv')\n",
    "\tcodebook.set_index(keys='variable', inplace=True)\n",
    "\tlabels = copy.deepcopy(param['variables'])\n",
    "\tlabel = 'short_name'                                             # default\n",
    "\tif ('label' in param and param['label'] == 'variable'): label = 'variable'\n",
    "\tif ('label' in param and param['label'] == 'full_name'): label = 'full_name'\n",
    "\tif ('label' in param and param['label'] == 'short_name'): label = 'short_name'\n",
    "\tif (label != 'variable'):\n",
    "\t\tfor idx, variable in enumerate(param['variables']):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tcodeRec = codebook.loc[variable]\n",
    "\t\t\t\tlabels[idx] = codeRec[label]\n",
    "\t\t\texcept:\n",
    "\t\t\t\tprint(\"variable not found in codebook.  variable:\", variable)\n",
    "\tparam['labels'] = labels\n",
    "    \n",
    "\tif (community):\n",
    "\t\twrite_INDEX_html(param)\n",
    "\t\twrite_GEO_CONFIG_js(param)\n",
    "\t\twrite_GEO_VARIABLES_js(community, param)\n",
    "\t\twrite_GEO_JSON_js(community, param)\n",
    "\t\n",
    "\tif (metros is not None):\n",
    "\t\twrite_ALL_METROS_INDEX_html(param)\n",
    "\t\twrite_ALL_METROS_GEO_CONFIG_js(param)\n",
    "\t\twrite_ALL_METROS_VARIABLES_js(metros, param)\n",
    "\t\twrite_ALL_METROS_JSON_js(metros, param)\n",
    "\t\n",
    "\t#local_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "\tservers = list(notebookapp.list_running_servers())\n",
    "\tservers1 = 'https://cybergisx.cigi.illinois.edu'+servers[0][\"base_url\"]+ 'view'\n",
    "\tservers2 = 'https://cybergisx.cigi.illinois.edu'+servers[0][\"base_url\"]+ 'edit'      \n",
    "\tcwd = os.getcwd()\n",
    "\tprefix_cwd = \"/home/jovyan/work\"\n",
    "\tcwd = cwd.replace(prefix_cwd, \"\")\n",
    "\tlocal_dir1 = servers1 + cwd\n",
    "\tlocal_dir2 = servers2 + cwd    \n",
    "\t#print(local_dir)\n",
    "\tfname =urllib.parse.quote('index.html')\n",
    "\ttemplate_dir = os.path.join(local_dir1, 'NAM_' + param['filename_suffix'])\n",
    "\t#url = 'file:' + os.path.join(template_dir, fname)\n",
    "\turl = os.path.join(template_dir, fname)    \n",
    "\twebbrowser.open(url)\n",
    "\tprint('To see visualization of your analysis, click the URL below:')\n",
    "\tprint(url)    \n",
    "\tprint('Advanced options are available in ')  \n",
    "\tprint(local_dir2 + '/'+ 'NAM_' + param['filename_suffix']+'/data/GEO_CONFIG_' + param['filename_suffix']+'.js')  \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\tstarted_datetime = datetime.now()\n",
    "\tdateYYMMDD = started_datetime.strftime('%Y%m%d')\n",
    "\ttimeHHMMSS = started_datetime.strftime('%H%M%S')\n",
    "\tprint('GEOSNAP2NAM start at %s %s' % (started_datetime.strftime('%Y-%m-%d'), started_datetime.strftime('%H:%M:%S')))\n",
    "\t\n",
    "\t#sample = \"downloads/LTDB_Std_All_Sample.zip\"\n",
    "\t#full = \"downloads/LTDB_Std_All_fullcount.zip\"\n",
    "\t#store_ltdb(sample=sample, fullcount=full)\n",
    "\tstore_census()\n",
    "    \n",
    "\tended_datetime = datetime.now()\n",
    "\telapsed = ended_datetime - started_datetime\n",
    "\ttotal_seconds = int(elapsed.total_seconds())\n",
    "\thours, remainder = divmod(total_seconds,60*60)\n",
    "\tminutes, seconds = divmod(remainder,60)\t\n",
    "\tprint('GEOSNAP2NAM ended at %s %s    Elapsed %02d:%02d:%02d' % (ended_datetime.strftime('%Y-%m-%d'), ended_datetime.strftime('%H:%M:%S'), hours, minutes, seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/cluster/hierarchy.py:830: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  return linkage(y, method='ward', metric='euclidean')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To see visualization of your analysis, click the URL below:\n",
      "https://cybergisx.cigi.illinois.edu/user/suhanmappingideas/view/geosnap-viz/GEOSNAP2NAM/NAM_SD_everything_4/index.html\n",
      "Advanced options are available in \n",
      "https://cybergisx.cigi.illinois.edu/user/suhanmappingideas/edit/geosnap-viz/GEOSNAP2NAM/NAM_SD_everything_4/data/GEO_CONFIG_SD_everything_4.js\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'title': \"Neighborhood Analysis: Kmeans, San Diego\",\n",
    "    'filename_suffix': \"SD_everything_4\",              # \"Albertville\"\n",
    "    'state_fips': None,\n",
    "    'msa_fips': \"41740\",                         # \"10700\"\n",
    "    'county_fips': None,\n",
    "    'years': [1980, 1990, 2000, 2010],           # Available years: 1970, 1980, 1990, 2000 and 2010\n",
    "    'method': \"kmeans\",                          # Aspatial Clustering: affinity_propagation, gaussian_mixture, hdbscan, kmeans, spectral, ward\n",
    "                                                 # Spatial Clustering: azp, max_p, skater, spenc, ward_spatial   \n",
    "    'nClusters': 8,                              # This option should be commented out for affinity_propagation, hdbscan and max_p \n",
    "    'variables': [\"p_nonhisp_white_persons\", \n",
    "                  \"p_nonhisp_black_persons\", \n",
    "                  \"p_hispanic_persons\", \n",
    "                  \"p_native_persons\", \n",
    "                  \"p_asian_persons\",\n",
    "                 ],\n",
    "    'Maps_of_neighborhood': True,                #choropleth map: Maps representing clustering result\t\t\n",
    "    'Temporal_change_in_neighborhoods': True,    #stacked chart: Temporal Change in Neighborhoods over years\t\t\n",
    "    'Parallel_Categories_Diagram_in_neighborhoods': True,\n",
    "}\n",
    "\n",
    "Clustering_viz(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
